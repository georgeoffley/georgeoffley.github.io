<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description>I make great projects using Python, C#, PHP, and JavaScript. Currently learning about AWS, Go, C++, and the graphics pipeline. I also love writing and well made movies. Check out my blog and my twitter to contact me!</description>
    <link>https://georgeoffley.com/</link>
    <atom:link href="https://georgeoffley.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 03 Nov 2021 13:15:29 -0400</pubDate>
    <lastBuildDate>Wed, 03 Nov 2021 13:15:29 -0400</lastBuildDate>
    <generator>Jekyll v3.8.4</generator>
    
      <item>
        <title>Messaging and Madness: Sending Messages with AMQP and Amazon MQ</title>
        <description>&lt;figure&gt;
    &lt;img src=&quot;https://georgeoffley-blog-images.s3.amazonaws.com/2021-10-30-messaging-and-madness/title_card.png&quot; /&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;table-of-contents&quot;&gt;Table Of Contents&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#amqp&quot;&gt;AMQP&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#amqp_amazon_mq&quot;&gt;AMQP and Amazon MQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#serialization&quot;&gt;Serialization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;introduction-&quot;&gt;Introduction &lt;a name=&quot;introduction&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;How do software systems talk to each other? Back-end systems can scale into giant melted together &lt;a href=&quot;https://youtu.be/NH-8L1iZq20&quot;&gt;Cronenberg monsters&lt;/a&gt;, often making up different tools and languages. So, communicating between these services can become an untenable challenge without some shared vocabulary. We can communicate in many ways, but today I wanted to talk about asynchronous messaging protocols and figure out how AWS can help.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3 id=&quot;amqp-&quot;&gt;AMQP &lt;a name=&quot;amqp&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;AMQP stands for Advanced Message Queuing Protocol. I’ve been working to implement it for some back-end software suites I’m building out to enable them to talk to each other. AMQP utilizes these things called &lt;em&gt;brokers&lt;/em&gt; to publish messages on, then on the other end, a receiving service subscribed to the same “channel” that we posted to can pick up that message.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://georgeoffley-blog-images.s3.amazonaws.com/2021-10-30-messaging-and-madness/hello-world-example-routing.png&quot; alt=&quot;Hello World Visualization&quot; /&gt;
via &lt;a href=&quot;https://www.rabbitmq.com/tutorials/amqp-concepts.html&quot;&gt;Rabbit MQ Tutorials&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let’s dive a little further down; the &lt;em&gt;publisher&lt;/em&gt; service publishes a message to an &lt;em&gt;exchange&lt;/em&gt; on a &lt;em&gt;broker&lt;/em&gt;. This exchange has &lt;em&gt;routes&lt;/em&gt; that lead to &lt;em&gt;queues&lt;/em&gt;, or “channels,” where the payload is published. We make sure to include the sending information with our message to be routed to the correct queue. The broker cannot see the message, although it might look into any metadata attached to the message from the publisher. This workflow asynchronously sends messages. Imagine a server version of a mail sorting machine shooting letters into the correct mail slot based on the address.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://georgeoffley-blog-images.s3.amazonaws.com/2021-10-30-messaging-and-madness/mail_sorting.gif&quot; alt=&quot;Mail Sorting Gif from MIB II&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When referring to a publisher, I mean some code that we utilize to connect and send a message. AMQP is programmable, so I can shape it to fit most situations. In this case, we need to send messages to our different software suites to trigger actions to happen. Learning this took some time, but it’s been simple to implement.&lt;/p&gt;

&lt;p&gt;There are different types of exchanges that we can use to make these services fit our needs. I’m going to explain what we use briefly.&lt;/p&gt;

&lt;p&gt;We use a &lt;em&gt;direct exchange&lt;/em&gt; utilizing &lt;em&gt;routing keys&lt;/em&gt; to bind queues to exchanges. Our code can use direct exchanges to distribute tasks to many different endpoints, but we used these direct exchanges to make direct routes between our services. Other types of exchanges can be used to broadcast messages. More information can be found &lt;a href=&quot;https://www.rabbitmq.com/tutorials/amqp-concepts.html&quot;&gt;here&lt;/a&gt;. For now, we’re going to focus on direct exchanges.&lt;/p&gt;

&lt;h3 id=&quot;amqp-and-amazon-mq-&quot;&gt;AMQP and Amazon MQ &lt;a name=&quot;amqp_amazon_mq&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;We touched on all that because I wanted to talk about &lt;a href=&quot;https://aws.amazon.com/amazon-mq/?amazon-mq.sort-by=item.additionalFields.postDateTime&amp;amp;amazon-mq.sort-order=desc&quot;&gt;Amazon MQ&lt;/a&gt;. Amazon MQ is a fully managed platform for setting up message brokers. Amazon MQ utilizes both RabbitMQ and Apache Active MQ for creating brokers. We’re sticking with Rabbit MQ for the time being.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://georgeoffley-blog-images.s3.amazonaws.com/2021-10-30-messaging-and-madness/amazon_mq_dash.png&quot; alt=&quot;Amazon MQ Dashboard&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here above, you can see you can easily set up a broker in just a few clicks. I left most of the settings on default, except for choosing “RabbitMQ” for our broker engine and setting some security up for accessing our management console.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://georgeoffley-blog-images.s3.amazonaws.com/2021-10-30-messaging-and-madness/rabbit_mq_dash.png&quot; alt=&quot;Rabbit MQ Management Console&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Once we get that, we have access to the RabbitMQ dashboard Amazon MQ created and is managing. Now that we have a broker set up, we can play with some code.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://georgeoffley-blog-images.s3.amazonaws.com/2021-10-30-messaging-and-madness/code.png&quot; alt=&quot;Code&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Above I use the library &lt;a href=&quot;https://github.com/celery/kombu&quot;&gt;Kombu&lt;/a&gt; to create some connections and send some stuff. I started by setting up our environment variables. Then created exchange and queue objects. Finally, I made our connection object and the producer object, and then we sent a simple “Hello” message.&lt;/p&gt;

&lt;h3 id=&quot;serialization-&quot;&gt;Serialization &lt;a name=&quot;serialization&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Serialization is &lt;a href=&quot;https://www.tutorialspoint.com/object_oriented_python/object_oriented_python_serialization.htm&quot;&gt;another blog post&lt;/a&gt;, but I chose to use JSON to serialize the payload. In the production software, I use a combination of JSON and &lt;a href=&quot;https://docs.python.org/3/library/pickle.html&quot;&gt;Pickle&lt;/a&gt; to serialize things like image data.&lt;/p&gt;

&lt;p&gt;Now we can see our message published on the queue I declared in our publisher service. An identical receiving service would be set up on the other side to read out messages sent to that queue.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://georgeoffley-blog-images.s3.amazonaws.com/2021-10-30-messaging-and-madness/results.png&quot; alt=&quot;Results&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;conclusion-&quot;&gt;Conclusion &lt;a name=&quot;conclusion&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;In conclusion, using Amazon MQ allows us to set up managed brokers for us to send messages. With AMQP as the broker engine, we have a lightweight message-sending workflow. Thanks for reading.&lt;/p&gt;

&lt;p&gt;-George&lt;/p&gt;
</description>
        <pubDate>Sat, 30 Oct 2021 12:00:00 -0400</pubDate>
        <link>https://georgeoffley.com/blog/messaging-and-madness-sending-messages-with-amqp-and-amazon-mq.html</link>
        <guid isPermaLink="true">https://georgeoffley.com/blog/messaging-and-madness-sending-messages-with-amqp-and-amazon-mq.html</guid>
        
        <category>AWS</category>
        
        <category>Python</category>
        
        <category>AMQP</category>
        
        
        <category>Blog</category>
        
      </item>
    
      <item>
        <title>Health Checking S3 and DynamoDB in AWS</title>
        <description>&lt;figure&gt;
    &lt;img src=&quot;https://georgeoffley-blog-images.s3.amazonaws.com/2021-03-03-checking-health-in-s3-and-dynamodb/cover.jpg&quot; /&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;table-of-contents&quot;&gt;Table Of Contents&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#problem&quot;&gt;Problem&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#s3_solution&quot;&gt;S3 Solution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#dynamo_solution&quot;&gt;DynamoDB Solution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;introduction-&quot;&gt;Introduction &lt;a name=&quot;introduction&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;A hybrid infrastructure has tons of exciting challenges. Although we host a great deal of our software in AWS at my company, we cannot do everything in the cloud. As such, we have tons of physical infrastructure as well. This hybrid infrastructure presents many challenges that we strive to overcome on the software team. One of the challenges we are working towards is imaging and utilizing software to detect our yields. This piece of that puzzle will focus on storage for our images.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;We decided that we would use a combination of services offered by AWS. The first is the Amazon Simple Storage Service or S3 for image storage and DynamoDB for holding metadata of said images. Given that we are getting information straight from hardware, many things might go wrong, from getting the pictures to when said pictures are pushed to AWS. This brings us to this evening’s question: How can I be sure these services are available for me to send stuff to?&lt;/p&gt;

&lt;h3 id=&quot;problem-&quot;&gt;Problem &lt;a name=&quot;problem&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Well, as it turns out, there are a few ways this can be done. For example, there are libraries out there that will scan health check websites to see if AWS has any service outages. This would not be a great way to do health checks for a production application. So, I decided to spike this problem and make something myself. I am not worried about AWS services being out as they have high availability using their different availability zones. I am more concerned about our endpoints failing, internet issues, or Cloverfield monsters. So, this needs to be explored.&lt;/p&gt;

&lt;h3 id=&quot;s3-solution-&quot;&gt;S3 Solution &lt;a name=&quot;s3_solution&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;A simple solution for checking the health of my resources was needed. Luckily, I quickly put something together using the &lt;a href=&quot;https://boto3.amazonaws.com/v1/documentation/api/latest/index.html&quot;&gt;Boto3 library&lt;/a&gt;, which is the AWS SDK for Python. This library gives us easy access to the AWS API for configuring and managing services. The first thing I did was create an object class to utilize the Client class in Boto3.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://georgeoffley-blog-images.s3.amazonaws.com/2021-03-03-checking-health-in-s3-and-dynamodb/client_object.png&quot; alt=&quot;Client Object&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We only need to pass in our access credentials and the services we want to create a client object for, and we get our client object back. Each turn in Boto3 allows for interacting with the Client class. The docs define the Client class as &lt;a href=&quot;https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#client&quot;&gt;“a low-level client representing whatever service”&lt;/a&gt;. In most cases, you would use it to access the various functions for interacting with the service.&lt;/p&gt;

&lt;p&gt;After that, I put together some simple logic to return some information on the resource we are looking for. In our case, we were trying to get access to a bucket where we will store images. This solution is enough to satisfy me that the resource exists, and I can communicate with it. Below is the code I used for S3.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://georgeoffley-blog-images.s3.amazonaws.com/2021-03-03-checking-health-in-s3-and-dynamodb/s3.png&quot; alt=&quot;S3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The code above sets up a new client instance and utilizes the &lt;a href=&quot;https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.head_bucket&quot;&gt;&lt;em&gt;head_bucket()&lt;/em&gt; function&lt;/a&gt;. This is great for seeing if a bucket exists and if the entity polling it has permissions to access it. In my case, I only need to be able to see if I get a message back. So, I pass in the bucket name, and I can receive a 200 message back from the server if the resource is there and I have access to it. I like this approach because it is dead simple, and I also get to utilize the custom exception that we get access to using the client object, which is the &lt;em&gt;NoSuchBucket&lt;/em&gt; exception. Using this exception allows us to be concise with our exceptions.&lt;/p&gt;

&lt;p&gt;There were some questions about the limitations on being able to use something like this. We expect to use this frequently to pole S3 and make sure that we can talk to our bucket. If AWS is not available, we need to turn off the spigot and stop our software from sending stuff to AWS and not lose messages in the void of space. That said, we will be polling a few times a second at least; luckily for us, &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/&quot;&gt;S3 upped their request rate to 3500 to add data and 5500 for retrieving data&lt;/a&gt;. This gives us plenty of room to be able to pole what we need.&lt;/p&gt;

&lt;h3 id=&quot;dynamodb-solution-&quot;&gt;DynamoDB Solution &lt;a name=&quot;dynamo_solution&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;With the client object that we created above, we can also use that to access DynamoDB. As such, the code is below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://georgeoffley-blog-images.s3.amazonaws.com/2021-03-03-checking-health-in-s3-and-dynamodb/dynamo.png&quot; alt=&quot;Dynamo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The above code snippet does the same thing as the S3 code does. We create a new instance, and we use the &lt;a href=&quot;https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb.html#DynamoDB.Client.describe_table&quot;&gt;&lt;em&gt;describe_table()&lt;/em&gt; function while passing in the table name&lt;/a&gt;. This function returns information about the table, including the status. Also, note that the &lt;em&gt;ResourceNotFoundException&lt;/em&gt; is another custom exception provided by the Dynamo Client object. This bit of code satisfies what I need to be able to check the status of a table. Yay!&lt;/p&gt;

&lt;p&gt;Using this method also has similar challenges. The &lt;em&gt;decribe_table()&lt;/em&gt; function uses up an eventually consistent read on your table. So, getting out-of-date data is possible if you are polling something you just created, so give it a second. If you are using a provisioned table in Dynamo, this method will take up one of your reads per second. We will need to make sure this is accounted for when we start designing our database.&lt;/p&gt;

&lt;h3 id=&quot;conclusion-&quot;&gt;Conclusion &lt;a name=&quot;conclusion&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;The above simple bit of code was a brief spike for a solution we needed to explore. This write-up was inspired by a lot of the help I received from my fellow AWS Community Builders. Checking the health and status of services is one of many things that we will build out using AWS. I am excited to keep up my learning and building. If you have seen or made other stuff to accomplish this type of work, let me know! I would love to learn more.&lt;/p&gt;
</description>
        <pubDate>Wed, 03 Mar 2021 09:00:00 -0500</pubDate>
        <link>https://georgeoffley.com/blog/checking-health-in-s3-and-dynamodb.html</link>
        <guid isPermaLink="true">https://georgeoffley.com/blog/checking-health-in-s3-and-dynamodb.html</guid>
        
        <category>AWS</category>
        
        <category>Python</category>
        
        
        <category>Blog</category>
        
      </item>
    
      <item>
        <title>Encrypting Your Environment Variables in Lambda with KMS</title>
        <description>&lt;figure&gt;
    &lt;img src=&quot;/assets/images/encrypt-lambda-envs.jpg&quot; /&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;table-of-contents&quot;&gt;Table Of Contents&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#key_management_system_in_aws&quot;&gt;Key Management System in AWS&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#customer_master_keys&quot;&gt;Customer Master Keys&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#kms_and_lambda&quot;&gt;KMS and Lambda&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#additional_notes&quot;&gt;Additional Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;introduction-&quot;&gt;Introduction &lt;a name=&quot;introduction&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Do you hate when &lt;a href=&quot;https://youtu.be/tO5sxLapAts&quot;&gt;gnomes steal your underpants&lt;/a&gt; for profit? I know I hate when those guys come out to steal my stuff. Unfortunately, I cannot help you prevent the theft of your undergarments, but I can help you protect some assets in AWS. Specifically, we are going to talk about encrypting environment variables in Lambda.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;In a previous article, I talked through about how to create a &lt;a href=&quot;https://georgeoffley.com//aws/go/creating-a-twitter-bot-using-aws-lambda-and-go.html&quot;&gt;Twitterbot using AWS Lambda&lt;/a&gt;. I mentioned that we would talk about encrypting environment variables in my last AWS article, and this is it. Encrypting stuff is a big topic and crucial for maintaining a secure environment and not just in Lambda.&lt;/p&gt;

&lt;p&gt;We all know what encryption is, an ancient method for converting information into a secret code that only the correct parties would have access to. Usually, this is in the form of a key which both parties have access and can use to encrypt and decrypt. Anyone else looking at it would not be able to tell the difference between it and white noise. Records of civilization using encryption go as far back as Egyptians in 1900 B.C. using it to encode messages on the &lt;a href=&quot;http://www.cypher.com.au/crypto_history.htm&quot;&gt;walls of tombs&lt;/a&gt;. Our modern solution for this ancient technique requires us to dive into yet another service that AWS offers, Key Management Services, or KMS.&lt;/p&gt;

&lt;h3 id=&quot;key-management-system-in-aws-&quot;&gt;Key Management System in AWS &lt;a name=&quot;key_management_system_in_aws&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Key Management service, in short, is a service that allows us to manage encryption keys for various AWS services or within your AWS applications. KWS gives you a central repository to easily create, manage, and rotate your encryption keys. If you are wondering, the act of rotating encryption keys is when you generate new keys, re-encrypt all the data using the new keys, and then delete the old keys. It is an essential service in AWS.&lt;/p&gt;

&lt;p&gt;KMS is considered a multi-tenant hardware security module or &lt;a href=&quot;https://en.wikipedia.org/wiki/Hardware_security_module&quot;&gt;HSM&lt;/a&gt;. It’s a blade server sitting on a rack that handles the numerous clients managing keys in AWS every day. The hardware is created in a way that many clients can use the hardware but still be virtually isolated. The keys are stored in memory and not written to disk as a security measure. This way if the hardware is powered down the keys are gone and thus inaccessible.&lt;/p&gt;

&lt;p&gt;AWS does provide a single-tenant solution for enterprise businesses called &lt;a href=&quot;https://aws.amazon.com/cloudhsm/&quot;&gt;CloudHSM&lt;/a&gt;. This gives more control to the client. Now, let’s have a small discussion about the captivating subject of standards in cryptography.&lt;/p&gt;

&lt;p&gt;In 1901 the National Institute of Standards and Technology was founded as a laboratory for promoting innovation and industrial competitiveness for the science and &lt;a href=&quot;https://www.nist.gov/topics/cybersecurity&quot;&gt;technology sector&lt;/a&gt;. Now a part of the U.S. Department of Commerce, these are the folks who set security standards for the stuff we use. In 2002 the E-Government Act was signed into law and then amended in 2014 to include new measures for &lt;a href=&quot;https://csrc.nist.gov/projects/risk-management/detailed-overview&quot;&gt;cybersecurity&lt;/a&gt;. This included several plans to beef up encryption standards, among them is the Federal Information Process Standards or FIPS. This program sets legal requirements for U.S. government systems and the systems for any contractors. The reason I bring all this is up is that KMS in its most basic form is compliant with FIPS 140-2 Level 2 compliant. If a client were to use the single-tenant CloudHSM solution for managing keys, then they comply with FIPS 140-2 Level 3. The different levels break down into levels of security through more aggressive security solutions. You can read about all the levels &lt;a href=&quot;https://en.wikipedia.org/wiki/FIPS_140-2&quot;&gt;here&lt;/a&gt;. A business would only need to worry about having their own CloudHSM if they are trying to comply with a specific regulation. For most of us, a regular KSM solution would work fine.&lt;/p&gt;

&lt;h3 id=&quot;customer-master-keys-&quot;&gt;Customer Master Keys &lt;a name=&quot;customer_master_keys&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Alright, so we know KMS is super cereal.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/100J2pbO98XSrm/giphy.gif&quot; alt=&quot;Super Cereal&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now how does it work? The primary resources in KMS are the Customer Master Keys or CMKs which are logical representations of the master keys. These master keys are used to encrypt and decrypt our data. They use what is called envelope encryption for securing keys and enabling encryption.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/9gycu8qyv3gfo20e792i.png&quot; alt=&quot;Key Hierarchy&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When you encrypt your data whatever you encrypted is protected but you also need to protect the encryption keys. Envelope encryption is the practice of encrypting plaintext data with a data key and then encrypting the data key with another key. The data keys are strings of data used to unlock crypto functions like authentication, authorization, and encryption. The role of the master key is to keep the &lt;a href=&quot;https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#enveloping&quot;&gt;data keys safe&lt;/a&gt;. The master keys are what is stored on the HSM and they are used to encrypt all the other keys. The CMKs you make also have metadata attached to them which track key ID, description, creation date, and key state. This metadata also includes the needed material for encryption and decrypting data.&lt;/p&gt;

&lt;p&gt;So, let’s see what we’re talking about.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/hcyg7crmmnwxfuzgj1nv.png&quot; alt=&quot;KMS Dash&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is the KMS dashboard where you can check out your keys. On the left, you notice that it defaults to the “Customer managed keys” menu where you can create your keys. There is also the option for AWS Managed Keys. These are keys created by AWS for various services that you use. For myself, I have a key for Lambda which is a default key I can use to encrypt environment variables. And a key for the &lt;a href=&quot;https://aws.amazon.com/cloud9/&quot;&gt;Cloud9 IDE AWS offers&lt;/a&gt;. Cloud9 is an awesome cloud-based IDE where you won’t run into issues with Posix permissions for &lt;a href=&quot;https://twitter.com/cloudbart/status/1291450566879727619&quot;&gt;stuff you make&lt;/a&gt;. Mini-rant over. The last option is for any “Custom key stores” you might have. Clients using AWS CloudHSM would come here to manage the keys they control within their cluster.&lt;/p&gt;

&lt;p&gt;So, let’s create a key&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/x0sv0evsmvjuisdl7p4n.png&quot; alt=&quot;Configure Key&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After we hit the &lt;em&gt;Create Key&lt;/em&gt; button we are taken to the &lt;em&gt;Configure Key&lt;/em&gt; page. Here we can choose which &lt;a href=&quot;https://docs.aws.amazon.com/kms/latest/developerguide/symm-asymm-choose.html&quot;&gt;type of encryption we want&lt;/a&gt;. Here we have a couple of options, &lt;strong&gt;Symmetric&lt;/strong&gt; and &lt;strong&gt;Asymmetric&lt;/strong&gt; encryption.&lt;/p&gt;

&lt;p&gt;Creating a symmetric key means we are going to create a 256-bit key that uses the same secret key to perform both the encryption and decryption processes. Something like an S4 bucket would be a great candidate for this kind of encryption which uses the &lt;a href=&quot;https://en.wikipedia.org/wiki/Advanced_Encryption_Standard&quot;&gt;AES-256 encryption standard&lt;/a&gt;. For me, I created a test key for encrypting environment variables using symmetric encryption.&lt;/p&gt;

&lt;p&gt;The other option is &lt;strong&gt;Asymmetric&lt;/strong&gt; encryption also known as public-key encryption. This will create an &lt;a href=&quot;https://en.wikipedia.org/wiki/RSA_(cryptosystem)&quot;&gt;RSA key pair&lt;/a&gt; used for encryption and decryption or it can also be used for signing and verification, but not both. With an asymmetric key, we create a public key used for encryption and a private key used for decryption. This we can create for something like an EC2 key pair for logging in via &lt;a href=&quot;https://docs.aws.amazon.com/crypto/latest/userguide/concepts-algorithms.html&quot;&gt;SSH to an instance&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The advanced options let you use a custom store from a CloudHSM a client might own or import a key from an external key management infrastructure. When importing something from an external key management service AWS lays out some rules about how you can’t use KMS to change the key material and how you assume responsibility for some of the things AWS assumes responsibility for when you use KMS to create keys. More information is &lt;a href=&quot;https://docs.aws.amazon.com/kms/latest/developerguide/importing-keys.html#importing-keys-considerations&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/msc48jt1kzlw1wvsg1gw.png&quot; alt=&quot;Add Label&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here we can add aliases for the keys. We can also add a description. We can also add &lt;a href=&quot;https://docs.aws.amazon.com/kms/latest/developerguide/tagging-keys.html&quot;&gt;tags&lt;/a&gt; that we might have created for tracking these assets through our billing set up.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/13i5ix96zyrlqsm85fss.png&quot; alt=&quot;Key Admin Permissions&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The next screen lets us give out permissions for our key. In a large environment, you can expect to assign this key to the needed administrator. That way only that user has &lt;a href=&quot;https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html#key-policy-default-allow-administrators&quot;&gt;permissions to administer the key using the KMS API&lt;/a&gt;. Another option you also get is whether to allow admins to delete this key we are making. For any environment, I am making I would probably uncheck this. From my non-cloud sys admin perspective when you have lots of keys distributed around to many different services to have a key deleted for any reason is a recipe for potential nightmare scenarios hunting down where the key was used and redeploying the data since there’s a good chance you’re locked out of getting to it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/1jnascp1p7oxz1dw00fu.png&quot; alt=&quot;Key Usage Perms&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The next screen lets us give basic permissions to use the CMK in cryptographic operations. So we can choose who can use this key to encrypt and decrypt assets. You can also add additional accounts here if we need another user that might not be on the list.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/ozwzl8iagix44ni9haoc.png&quot; alt=&quot;Review&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, we can review and make changes to the key policy. AWS creates these rules via a JSON file. So, if you know how to navigate through the fields and understand what you are changing you are free to change the policy as you see fit. I would suggest using the GUI to do anything rather than changing the JSON directly. Unless you know what, it is you are doing. Screw around and find out at your peril.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/fWgwMmkmF8VUZ6iGPb/giphy.gif&quot; alt=&quot;Peril&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;kms-and-lambda-&quot;&gt;KMS and Lambda &lt;a name=&quot;kms_and_lambda&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;O.K. we spent a bunch of time talking about a bunch of nerd stuff. I just wanted to encrypt my environment variables. What is all this? We are almost there I promise.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/b44FwP4st6v3G/giphy.gif&quot; alt=&quot;Peril&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now that we have a CMK set up let’s go into Lambda. Maybe we go into a new function that we created to test this out. Then we go into the environment variables. Now we can talk a little about how Lambda works and what impacts there are when we encrypt environment variables. Now Lambda is essentially a service that runs a single instance when called. So, no one sees your environment vars other than when a user is in the console. That said if you are sending API requests with keys and secrets anyone who might be listening on the line might be able to see it. Which is why we do all this stuff. So, before we send API secrets to Lambda lets encrypt it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/0ctwn8zocbq8n4uuuwws.png&quot; alt=&quot;Env Var Menu&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So, when we go to make our envs we have the option of encrypting them. This will encrypt them in transit and on the console too. If you notice I already created a variable and encrypted it. Under the value, there is just a random string of gibberish to the naked eye but with the key, I can decrypt the value and get the test key value. If we add a new variable, we can check the &lt;em&gt;Enable helpers for encryption in transit&lt;/em&gt; under the &lt;em&gt;Encryption configuration&lt;/em&gt; section which brings up the &lt;em&gt;Encrypt&lt;/em&gt; button. In that section, we also get the option of using the default Lambda key that AWS creates or one of the CMKs we made earlier. I mentioned this before, but Lambda has a default key that you can use for encrypting environment variables. Makes it easy to encrypt environment variables without setting up additional CMKs. I chose to use a CMK to demonstrate KMS but using the Lambda key would probably be fine if you only have a few. When you start to scale, and you need keys for tons of stuff is where I would say using CMKs is a good idea. It gives you a lot more options for tracking and auditing.&lt;/p&gt;

&lt;p&gt;After hitting the &lt;em&gt;Encrypt&lt;/em&gt; button we get a pop up which gives us the execution policy in the form of a JSON readout. In addition to that, we get one of my favorite things AWS gives you, the code to access your keys. I’m lazy and I will always appreciate being given the code to decode rather than digging through the API.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/1rc2ugwev2g14dcjgoh2.png&quot; alt=&quot;Decrypt Code&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So, I’m just going through how to decrypt and utilize your keys within your Lambda function. You can do a bit more with the API and I suggest you check out the reference &lt;a href=&quot;https://docs.aws.amazon.com/kms/latest/APIReference/Welcome.html&quot;&gt;here&lt;/a&gt;. Similar to when you’re looking for your unencrypted env variable you can use the &lt;em&gt;os.environ()&lt;/em&gt; function to grab our variable. Accept now we have just a long string of gibberish. Here is where we use the &lt;strong&gt;boto3&lt;/strong&gt; library to do some stuff.&lt;/p&gt;

&lt;p&gt;Boto3 is the &lt;a href=&quot;https://github.com/boto/boto3&quot;&gt;AWS SDK for Python&lt;/a&gt;. Here we look for the &lt;em&gt;kms&lt;/em&gt; service and use the built-in &lt;a href=&quot;https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/kms.html#client&quot;&gt;client class&lt;/a&gt; for accessing the KMS functions. Then you can see we use the &lt;a href=&quot;https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/kms.html#KMS.Client.decrypt&quot;&gt;&lt;em&gt;decrypt()&lt;/em&gt; function&lt;/a&gt; for decrypting the ciphertext we pass into it. The code also imports the &lt;strong&gt;b64decode&lt;/strong&gt; class from the &lt;a href=&quot;https://docs.python.org/3/library/base64.html&quot;&gt;bas64 module&lt;/a&gt; which we use to decode the &lt;em&gt;Encrypted&lt;/em&gt; var we grabbed. After that, we need to set our &lt;em&gt;EncryptionContext&lt;/em&gt; which is a set of non-secret key-value pairs which represent additional authentication data. The options passed in need to match the same context that was used for encrypting the data.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;QuickNote&lt;/em&gt;
You should know that these are for symmetrical CMKs which are called symmetric because they use the same shared key for encryption and decryption. A standard asymmetric key does not support an encryption context. I used symmetric encryption for these keys so that’s what I am going through.&lt;/p&gt;

&lt;p&gt;Finally, we can decode the ciphertext into plaintext using the &lt;em&gt;decode()&lt;/em&gt; method. After all that we have access to our decrypted key using the &lt;em&gt;Decrypted&lt;/em&gt; variable. As mentioned in the pictured code it’s a good idea to put all this somewhere at the beginning outside the function handler. That way we can have universal access to the decrypted key.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;QuickNote&lt;/em&gt;
You might notice that we grab some additional variables using the &lt;em&gt;os.environ()&lt;/em&gt; function. These are built-in in runtime environment variables which we can use to access some metadata from within the Lambda function. Check them out &lt;a href=&quot;https://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html#configuration-envvars-runtime&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Yay, now we can do stuff with our environment variables like pass them along to API calls. Congrats. Celebrate somehow.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/3ornkdtVzQfIRpwfug/giphy.gif&quot; alt=&quot;Please excuse the use of light skinned Aunt Viv&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;conclusion-&quot;&gt;Conclusion &lt;a name=&quot;conclusion&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;So now you know how to &lt;a href=&quot;https://youtu.be/R0IUR4gkPIE&quot;&gt;protect ya neck&lt;/a&gt; and encrypt ya stuff. Now encryption is a big topic. This is just one small sliver that might be relevant to using AWS Lambda. There is a long history related to cryptography. There is this great book called &lt;a href=&quot;https://www.amazon.com/dp/B004IK8PLE/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1&quot;&gt;The Code Book by Simon Singh&lt;/a&gt; which delves deep into the history and most ancient implementations of cryptography. I highly recommend it for the power nerds among us who like reading about cryptography.&lt;/p&gt;

&lt;p&gt;Creating policies that include encrypting your environment variables means better security and peace of mind. Lamba is a powerful engine and I am enjoying using it so far. My &lt;a href=&quot;https://twitter.com/TheTechBruh&quot;&gt;Twittterbot&lt;/a&gt; has been running for weeks and it’s cringy as hell so I think I’m doing something right. Now I have the tools to encrypt my API keys and secrets.&lt;/p&gt;

&lt;h3 id=&quot;additional-notes-&quot;&gt;Additional Notes &lt;a name=&quot;additional_notes&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;One other service that you can also check out is the &lt;a href=&quot;https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-user-guide.html?icmpid=docs_cloudtrail_console&quot;&gt;CloudTrail&lt;/a&gt;. You can use CloudTrail and attach them to CMKs so that they can be audited. Cloud trail can keep logs of access which can be used in audits. Very useful for clients with a lot of assets to manage.&lt;/p&gt;

&lt;p&gt;One other additional note is for those who use the &lt;a href=&quot;https://aws.amazon.com/cli/&quot;&gt;AWS CLI&lt;/a&gt; there are some commands which might come in handy to know. If you are also studying for an AWS Developer certification you will also need to know these.&lt;/p&gt;

&lt;p&gt;Commands:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;aws kms create-key - creates a unique customer-managed CMK in your AWS
aws kms encrypt - encrypts plaintext into ciphertext by using a CMK
aws kms decrypt - decrypts ciphertext that was encrypted by a KMS customer master key
aws kms re-encrypt - decrypts ciphertext and then re-encrypts it with KMS
aws kms enable-key-rotation - enables automatic rotation of the key material for the specified symmetric CMK. This cannot be done on a CML made by another account
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Fri, 04 Sep 2020 16:30:00 -0400</pubDate>
        <link>https://georgeoffley.com/blog/encrypting-your-envioronment-variables-in-lambda-with-kms.html</link>
        <guid isPermaLink="true">https://georgeoffley.com/blog/encrypting-your-envioronment-variables-in-lambda-with-kms.html</guid>
        
        <category>KMS</category>
        
        <category>AWS</category>
        
        <category>Lambda</category>
        
        
        <category>Blog</category>
        
      </item>
    
      <item>
        <title>Working with Context in Go</title>
        <description>&lt;figure&gt;
    &lt;img src=&quot;/assets/images/working-with-context-in-go.jpg&quot; /&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;table-of-contents&quot;&gt;Table Of Contents&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#context_interface&quot;&gt;Context Interface&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#context_in_context&quot;&gt;Context in context&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#context_background&quot;&gt;Context.Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#context_todo&quot;&gt;Context.TODO&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#context_withcancel&quot;&gt;Context.WithCancel&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#context_withDeadline&quot;&gt;Context.WithDeadline&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#context_withtimeout&quot;&gt;Context.WithTimeout&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#context_withvalue&quot;&gt;Context.WithValue&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;introduction-&quot;&gt;Introduction &lt;a name=&quot;introduction&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;When you’re having a breakdown caused by the combination of burnout and existential pain, do you get annoyed that your harried cries into the void go unanswered? Well, I can’t help with that, but I can suggest some methods for timing out calls to external or internal services. I’ve been doing research and playing with some of the standard libraries in Go and one of them I find most useful is the context library. Used to get some control over a system that might be running slowly for whatever reason or to enforce a certain level of quality for service calls this small library is a standard for a reason. For any production level systems to keep good flow control the context library is going to be necessary.
&lt;!--This is a test--&gt;
&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;Created by &lt;a href=&quot;https://twitter.com/Sajma&quot;&gt;Sameer Ajmani&lt;/a&gt; and &lt;a href=&quot;https://vimeo.com/115309491&quot;&gt;introduced in 2014&lt;/a&gt;, the context library become a standard library with Go 1.7. If you have looked through some Go library source code you can find tons of examples &lt;a href=&quot;https://github.com/mongodb/mongo-go-driver/blob/v1.4.0/mongo/client.go#L96&quot;&gt;requiring a context to be passed along&lt;/a&gt;. This is just one I’ve used recently. A &lt;em&gt;context&lt;/em&gt; is a deadline you can pass into a running process in your code. This deadline can indicate to a process to stop running and return after a condition is met. This becomes useful when reaching out to external APIs, databases as shown above, or system commands.&lt;/p&gt;

&lt;p&gt;The following supposes that the reader knows about goroutines and channels and how they work together. I am going to deep dive into concurrency after writing about context as the context library is part of concurrency. For now, though, goroutines are lightweight threads that can be started for processes and channels are the pipelines used to pass data between these new processes.&lt;/p&gt;

&lt;h3 id=&quot;context-interface-&quot;&gt;Context Interface &lt;a name=&quot;context_interface&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;The context library defines a new interface called Context. The Context interface has some interesting fields laid out below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/3zgq8cmkrprdfgo66niv.png&quot; alt=&quot;Context Interface&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;Deadline&lt;/em&gt; field returns the expected time the work is finished and indicates when the context should be canceled.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;Done&lt;/em&gt; field is a channel that is closed when work done for the context should be canceled. This operation can happen asynchronously. The channel can return as nil if the associated context can never be canceled. Different context types will arrange for work to be canceled depending on the circumstances, which we will get into.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Err&lt;/em&gt; will return nil until Done is closed. After which &lt;em&gt;Err&lt;/em&gt; will either return &lt;em&gt;Canceled&lt;/em&gt; if the context was canceled or &lt;em&gt;DealineExceeded&lt;/em&gt; if the context’s deadline has passed.&lt;/p&gt;

&lt;p&gt;The Value field is a key-value interface which will return a value associated with the context as a key or nil if there was no value associated. Values should be used carefully as they are not for passing parameters into a function but for &lt;a href=&quot;https://github.com/golang/go/blob/master/src/context/context.go#L185&quot;&gt;request-scoped data transits processes and API boundaries&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;context-in-context-&quot;&gt;Context in context &lt;a name=&quot;context_in_context&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;When creating a context in Go it is easy to write out a static context to store and reuse. So far as I can tell from my research this is not the optimal way to work with the context library. Context should take the form needed for each use. It should be shapeless, or in the words of &lt;a href=&quot;https://youtu.be/cJMwBwFj5nQ&quot;&gt;Bruce Lee be like water&lt;/a&gt;. Your context should flow through your code and evolve depending on the need.&lt;/p&gt;

&lt;p&gt;There are some exceptions to this. For higher-level processes, you can pass in an empty context when you do not yet have a context in which to pass. These can work as placeholders before being refactored.&lt;/p&gt;

&lt;h3 id=&quot;contextbackground-&quot;&gt;Context.Background &lt;a name=&quot;context_background&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;The “Background” function returns an empty non-nil context. There is no associated deadline and no cancelation to speak of. This can be typically used in the main function, for testing, or for creating a top-level context to be made into something else. Looking into the source code you can see that it doesn’t have any logic other than returning an &lt;a href=&quot;https://github.com/golang/go/blob/master/src/context/context.go#L208&quot;&gt;empty context&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/8g9hh8bxgsybws10ftld.png&quot; alt=&quot;Context Background&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;QuickNote:&lt;/em&gt;
Typically, the context is named &lt;em&gt;ctx&lt;/em&gt; when it is declared. I’ve seen this in most implementations of context so if you come across &lt;em&gt;ctx&lt;/em&gt; in random spots in source code there’s a good chance that it is referring to a context.&lt;/p&gt;

&lt;h3 id=&quot;contexttodo-&quot;&gt;Context.TODO &lt;a name=&quot;context_todo&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;The &lt;em&gt;TODO&lt;/em&gt; function does the same thing. It returns an empty non-nil context. This again is a use case for higher-level functions that may not yet have a function available to use them. In many cases, this would be used as a placeholder when extending your program to use the context library. If you checked out the talk by Sameer Ajmani about the introduction of the context library while refactoring their code at Google they would use the &lt;em&gt;context.TODO&lt;/em&gt; to start introducing context into the Google code base without breaking anything.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;QuickNote:&lt;/em&gt;
One thing I will also mention is that somewhere along the way it was suggested that the &lt;em&gt;TODO&lt;/em&gt; would be compatible for use in static analysis tools for seeing context propagation across a program. This from what I can tell might have been an off-hand comment from the person who wrote out the notes in the source code. I’ve been looking for the last couple of days and &lt;a href=&quot;https://go-review.googlesource.com/c/go/+/130876/&quot;&gt;from what I can tell no such tool yet exists&lt;/a&gt;. I would investigate how to create such a tool but I’m going to go watch a movie instead.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/iu484psunf8fgrlgqwe8.png&quot; alt=&quot;Context.TODO&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;contextwithcancel-&quot;&gt;Context.WithCancel &lt;a name=&quot;context_withcancel&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Let’s say I’m building a website to review movies. There is a myriad of APIs designed for serving movie information. One of the recent ones I’ve come across is the &lt;a href=&quot;https://ghibliapi.herokuapp.com/#section/Studio-Ghibli-API&quot;&gt;Studio Ghibli API&lt;/a&gt; which is a public API we can just grab stuff from. So, for the special section of the website for Studio Ghibli movies, we’ll use this. The &lt;em&gt;WithCancel&lt;/em&gt; function returns a copy of the parent context passed into it with a new &lt;em&gt;Done&lt;/em&gt; channel. The new &lt;em&gt;Done&lt;/em&gt; channel is closed either when the cancel function is called or when the parent context’s &lt;em&gt;Done&lt;/em&gt; channel is closed. Whichever event happens first.&lt;/p&gt;

&lt;p&gt;Below is an example in action:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/vk990lim7irgfmgqjm4w.png&quot; alt=&quot;Context.WithCancel&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here we are going to simulate a process that is hanging up using the &lt;em&gt;longRunningProcess&lt;/em&gt; function. In this example, the function is screwing up but we must run it before we request the JSON data from the API. The “longRunningProcess* function will return an error that will cause the &lt;em&gt;cancel()&lt;/em&gt; function within the context to fire.&lt;/p&gt;

&lt;p&gt;For the &lt;em&gt;ghibliReq&lt;/em&gt; function we will set up a simple HTTP request using the API and pass a string for locating stuff from the API. Once we set up the request, we have a case statement which will receive channel data. Depending on what happens first the select statement will be sent either the current time or the “Done” channel from the passed in context. If the &lt;em&gt;Done&lt;/em&gt; channel is closed we error out, if not we will return the status code from our request.&lt;/p&gt;

&lt;p&gt;Our main code starts with setting up the context with a new &lt;em&gt;Background()&lt;/em&gt; context which is then passed into a &lt;em&gt;WithCancel()&lt;/em&gt; context. The new &lt;em&gt;ctx&lt;/em&gt; was passed in an empty context so nothing has happened yet. We then create a new goroutine to create a new thread and call our &lt;em&gt;longRunningProcess&lt;/em&gt;. Once that is called we check for errors, which will return since we engineered it that way, and if there are errors we can call the &lt;em&gt;cancel()&lt;/em&gt; function in our context. Finally, we use our context to call our request. After we run this we find that the request errored out since it took too long and the &lt;em&gt;cancel()&lt;/em&gt; function was called.&lt;/p&gt;

&lt;p&gt;In this example, we are running our &lt;em&gt;longRunningProcess&lt;/em&gt; before our request because that is needed before we call our request. If the function errors out we need to be able to call “cancel()” so that we can error out the &lt;em&gt;ghibliReq()&lt;/em&gt; function. The way we set it up we are calling &lt;em&gt;cancel&lt;/em&gt; for our context before the function has a chance to run. This is intentional to show how the cancel works. We could easily change the &lt;em&gt;time.Sleep()&lt;/em&gt; in &lt;em&gt;longRunningProcess&lt;/em&gt; to say 1000 milliseconds and our request function will run before &lt;em&gt;cancel()&lt;/em&gt; is called but in a production environment if the goal is to make sure we maintain the flow of the call stack we would make sure we’re not returning errors and not calling &lt;em&gt;cancel()&lt;/em&gt; for this context.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;QuickNote:&lt;/em&gt;
Keep in mind that a context-specific call shouldn’t be a blocking action unless necessary. It’s all about keeping stuff running.&lt;/p&gt;

&lt;h3 id=&quot;contextwithdeadline-&quot;&gt;Context.WithDeadline &lt;a name=&quot;context_withDeadline&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;The &lt;em&gt;WithDeadline&lt;/em&gt; function requires two arguments. One is the parent context and the other is a new time object. The function will take the parent context and adjust it to meet the new time object which was passed in. There are a couple of caveats. If you pass in a context that is already earlier than the passed in the time object then the source code will pass just return a &lt;em&gt;WithCancel&lt;/em&gt; context with the same cancellation requirements as the parent which you can see &lt;a href=&quot;https://github.com/golang/go/blob/master/src/context/context.go#L430&quot;&gt;in the source&lt;/a&gt;. The &lt;em&gt;Done&lt;/em&gt; channel is closed after the new deadline expires. You can also manually return the &lt;em&gt;cancel&lt;/em&gt; function or it will close when the parent context’s &lt;em&gt;Done&lt;/em&gt; channel is closed. Whichever of those events happens first.&lt;/p&gt;

&lt;p&gt;Below we can go through how the &lt;em&gt;WithDeadline&lt;/em&gt; works:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/nwwcwgh95cejnb5kjdsh.png&quot; alt=&quot;Context.WithDeadline&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We’re going to continue with the idea that we are putting together a movie review site. To be honest it would not be far off character of me to start a website dedicated to talking exclusively about Studio Ghibli movies. The example above is doing something like the &lt;em&gt;withCancel&lt;/em&gt; example. We are going to reuse a function to demonstrate our context. Reuse the stuff that works, save yourself some time. We are going to make a request and return the status of said request. The difference is how we handle our context.&lt;/p&gt;

&lt;p&gt;Hypothetically, we need to create a whole bunch of these cascading requests and we want to make sure that everything is happening on time throughout the call stack. To keep track of time and gracefully error out when needed we can continue to use the deadlines and augment the time for the additional calls. In our example, we create a &lt;em&gt;Background&lt;/em&gt; context, then pass that in along with a new time. Now we get a returned context in our &lt;em&gt;ctx&lt;/em&gt; variable for about 1 second. In our example, if the request process takes longer than 1 second our context calls the cancel function and closes the &lt;em&gt;Done&lt;/em&gt; channel causing the request to error out.&lt;/p&gt;

&lt;p&gt;We can see that this is dependent on the standards that we set. Setting a time implies that you have a decent idea about how long something should take. Which can be dependent on your server availability, internet connection, hardware constraints, etc. I have also seen people grumble about certain service level agreements guaranteeing the return of assets within a certain time frame. With the aim of usability in mind using context, deadlines can help to ensure that we can pull information at a reasonable amount of time and return if not.&lt;/p&gt;

&lt;h3 id=&quot;contextwithtimeout-&quot;&gt;Context.WithTimeout &lt;a name=&quot;context_withtimeout&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;The next relevant function is the &lt;em&gt;WithTimeout&lt;/em&gt; function. This is a slight variation from the &lt;em&gt;WithDeadline&lt;/em&gt; function. With a need to make something original in mind the &lt;em&gt;WithTimeout&lt;/em&gt; simply returns a &lt;em&gt;WithDeadline&lt;/em&gt; context with the time argument passed in added to the deadline. In other words, it acts similar to the &lt;em&gt;WithDeadline&lt;/em&gt; in that it will take the parent and augment the time to return a derived context with the new time added to the time before the &lt;em&gt;cancel&lt;/em&gt; function is called and the &lt;em&gt;Done&lt;/em&gt; channel is closed. I’ll make this example even simpler:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/dcw4vhshlsephh1c19na.png&quot; alt=&quot;Context.WithTimeout&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Same as the example before we set the timeout to close the “Done” channel after the allotted time. In our case, if after a half-second, we’re still waiting for the call we timeout. I love the HTTP go library because it has a built-in function for returning a shadow copy of the request with the &lt;a href=&quot;https://golang.org/src/net/http/request.go?s=12980:13039#L341&quot;&gt;new context added&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;contextwithvalue-&quot;&gt;Context.WithValue &lt;a name=&quot;context_withvalue&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;The last bit of the source I am going to touch on is the &lt;em&gt;ContextWithValue&lt;/em&gt; function. This one is a bit controversial since the nature of it, from what I can tell, goes against what the context should be. A context should be a way to ensure that we keep data flowing to and from our programs. The value part of the context though can be used to carry information back and forth. The function allows you to pass in a key-value interface to pass around with your calls.&lt;/p&gt;

&lt;p&gt;From the original post about context &lt;a href=&quot;https://blog.golang.org/context&quot;&gt;“WithValue provides a way to associate request-scoped values with a context”&lt;/a&gt;. I’m going to talk a little about what it shouldn’t be used for. Most articles or tutorials I came across seem to agree that passing information that lives outside of the request itself was a bad idea. DB connections, function arguments, anything that is not created and destroyed within that request is probably not a great design pattern. That said passing values along your context can be useful.&lt;/p&gt;

&lt;p&gt;Let’s check out some code:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/nrbebpw31tc4nmwjj285.png&quot; alt=&quot;Context.WithValue&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We’re going to use the same code from the last example. Only in this case, we are going to create a new function which will calculate a fake request ID. Say I want to keep a database of all my requests, because… I don’t know, I’m a psychopath. Or I work for the NSA and I’m making some spyware to look in on my ex in the name of national security. And because they don’t train me in operational intelligence, I don’t know how to discern the data that indicates something and white noise, so I collect everything. Even innocuous calls to an open API for looking up animated movie information. I’m very tired right now.&lt;/p&gt;

&lt;p&gt;In our example we do the same as above; set up a context with a timeout for half a second. Only now we have a helper method that will calculate a new request ID and we will use the context to pass that ID along within the context as a new interface that we can access and do stuff with. In this fake scenario, we would log this and close out the context. This will conform to our self-imposed standard of keeping only information relevant to that call. Yay information!&lt;/p&gt;

&lt;p&gt;There is a lot more to be explored about passing along values within a context. I have seen articles where middleware is used to do stuff in between two services to make something work better. I might dig deeper into this and since it’s a bit outside the scope of this I might write about it later. Who knows, I need sleep.&lt;/p&gt;

&lt;h3 id=&quot;conclusion-&quot;&gt;Conclusion &lt;a name=&quot;conclusion&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;The context library helps to add some sanity to calls in our program. When designing a program incorporating a context in our functions should happen as early as possible. As mentioned, before it is easy to create our function with a &lt;em&gt;TODO&lt;/em&gt; as a placeholder and go back when refactoring. It was also mentioned that programs should be created to fail gracefully as well. Take it from someone who spent a long time creating vague fail messages which no one can understand including me. A user should not have to know that a call to something failed just that they aren’t getting their movie title in half a second.&lt;/p&gt;

&lt;p&gt;A cool way to picture how useful these contexts can be was touched on in Sameer’s talk. He spoke about the practice of hedged calls where you call out redundant services and take the one which takes less time. It’s all about speed and optimization with them Google people. That is one way in which creating a context to flow through your program would be helpful. When one comes back you cancel out the other which releases the resources that thread might have been using up. The context is a small but very powerful library, it should be used often and with plenty of thought and planning into how it should flow into your program. My hope after reading this is that we all come away with a better understanding of context and how we can use it! If you liked this, had questions and or comments, or you just want to berate me on how much the Last Jedi sucked (it was an imperfect but powerful movie for a world not yet ready for it) hit me up on &lt;a href=&quot;https://twitter.com/georgeoffley&quot;&gt;Twitter&lt;/a&gt;! I love topical references.&lt;/p&gt;
</description>
        <pubDate>Mon, 17 Aug 2020 21:00:00 -0400</pubDate>
        <link>https://georgeoffley.com/blog/working-with-context-in-go.html</link>
        <guid isPermaLink="true">https://georgeoffley.com/blog/working-with-context-in-go.html</guid>
        
        <category>concurrency</category>
        
        <category>Go</category>
        
        
        <category>Blog</category>
        
      </item>
    
      <item>
        <title>Creating a Twitter Bot Using AWS Lambda and Go</title>
        <description>&lt;figure&gt;
    &lt;img src=&quot;/assets/images/twitter-bot-aws-lambda.jpg&quot; /&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;table-of-contents&quot;&gt;Table Of Contents&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#twitter_setup&quot;&gt;Twitter App Set-Up&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#twitter_bot_code&quot;&gt;Twitter Bot Code&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#lambda_function&quot;&gt;Setting up a Lambda Function&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;introduction-&quot;&gt;Introduction &lt;a name=&quot;introduction&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Most people have heard of AWS and developers have started learning how they can use it to further augment the quality of their projects. Recently I have begun the process of becoming one of those people. So far it has been an enlightening deep dive into the different services they offer. It’s hard to get your bearings with something as huge as AWS so for my learning journey I decided to focus on projects I thought would be cool and see how AWS might help facilitate what I build.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;One project I have been wanting to get into is a Twitter bot using a new language I have been learning, Go. A simple twitter bot is easy to set up. Their API makes it easy to interface with and there are thousands of libraries that utilize this &lt;a href=&quot;https://github.com/search?q=twitter&quot;&gt;API&lt;/a&gt;. I am all for anything which makes my job easier. Let’s see how much easier still I can make this using AWS Lambda.&lt;/p&gt;

&lt;p&gt;Lambda is a compute service for running code on the cloud. With which you can create functions and triggers to start those functions and Lambda runs your code without having to provision a server. It’s serverless. I realized this is uniquely appropriate for things like a regularly scheduled Twitter bot. With Lambda I do not need to spin up an EC2 or a local VM instance and continually run my bot. I can simply set a schedule and create the bot and Lambda starts up, runs my function, and powers down.&lt;/p&gt;

&lt;p&gt;Lambda’s free services are also a great use case because the first 1 million requests per month are free. After which you pay $0.20 per additional million requests; The first 400,000 GB seconds are also free and $0.0000166667 for every GB second after that. This Twitter bot is a quote regurgitation service so there is very little chance of it ever exceeding any of that.&lt;/p&gt;

&lt;h3 id=&quot;twitter-app-set-up-&quot;&gt;Twitter App Set-Up &lt;a name=&quot;twitter_setup&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;The Twitter API has been in v1.1 since 2016. In 2020 however, they began rolling out v2. Rebuilt from the ground up they also overhauled their &lt;a href=&quot;https://developer.twitter.com/en/pricing&quot;&gt;pricing&lt;/a&gt;. For our purposes, we can still use the free tier. Let’s talk about the Twitter end first. If you go to &lt;a href=&quot;https://developer.twitter.com/&quot;&gt;Twitter’s Developer portal&lt;/a&gt; you can head to the dashboard and set up a new app. We are assuming here that you have already set up a developer account with Twitter. If you have not, &lt;a href=&quot;https://developer.twitter.com/en/apply-for-access&quot;&gt;check this out&lt;/a&gt; on how to get started.&lt;/p&gt;

&lt;p&gt;Once we get the developer account set up we can head to the &lt;a href=&quot;https://developer.twitter.com/en/apps&quot;&gt;Apps portal&lt;/a&gt;. Here we can click the top right to create a new app.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/zqru6dir2uinvyexvhoa.png&quot; alt=&quot;Create App Dashboard&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There is some information required for setting up an app. You need to provide information about the app and a website if the app is going to be attached to one. Once that is set up, we can grab our keys and tokens so and start accessing Twitter through the API library.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/vt1cuaqs9owf8rcuffcd.png&quot; alt=&quot;Keys and Tokens&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Quick note:&lt;/em&gt;
Make sure to check the permissions for your Twitter App. By default, the permissions are set to read. So, if by the end you see permission errors from the API this might be the culprit. Make sure to set the permissions to the least necessary. Here we are making a bot to post Tweets, so we need “Read and write” permissions. I do not need the ability to DM anyone, so I chose “Read and write”. So, go to the “Keys and tokens” section, copy your consumer key, consumer secret, access token, and access secret. Now that we got our credentials, we are ready to party&lt;/p&gt;

&lt;h3 id=&quot;twitter-bot-code-&quot;&gt;Twitter Bot Code &lt;a name=&quot;twitter_bot_code&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Creating a custom library for dealing with the API is preferable for any production system as it allows for the customization needed. For our purposes, we only need to open a stream and send a tweet through it to post. So, I decided to use the &lt;a href=&quot;https://github.com/ChimeraCoder/anaconda&quot;&gt;Anaconda Library&lt;/a&gt; which still uses v1.1 of the Twitter API.&lt;/p&gt;

&lt;p&gt;The first thing we do is set up our development environment. I use &lt;a href=&quot;https://code.visualstudio.com/&quot;&gt;VS Code&lt;/a&gt; with the &lt;a href=&quot;https://code.visualstudio.com/docs/languages/go&quot;&gt;Go plugin&lt;/a&gt; to help me. I also use a Windows environment to make everything. Later I will circle back to why this isn’t a great idea. We are also going to use Go modules to keep track of our dependencies. Go 1.11 and up can support Go modules and anything above Go 1.13 is going to use them &lt;a href=&quot;https://blog.golang.org/using-go-modules&quot;&gt;by default&lt;/a&gt;. With that in mind, we set up our file directory as such&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bot&lt;/li&gt;
  &lt;li&gt;go.mod&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We CD to the root of our project and run:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;go mod init bot/main
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we have our directory and our mod file which is where our dependencies are housed. Next, we create our bot file.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bot&lt;/li&gt;
  &lt;li&gt;go.mod&lt;/li&gt;
  &lt;li&gt;bot.go&lt;/li&gt;
  &lt;li&gt;quotes.json&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You will also notice that there is a JSON file called &lt;em&gt;quotes.json&lt;/em&gt; this is where we will store our quotes for now. Now we can get started building. The first thing is we add our dependencies. I added a few here and I will explain the need for them as we go along.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/0yitj4zav5hmjzxahuil.png&quot; alt=&quot;Dependancies&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The next part you will see is our data types we created for the bot.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/brtnop70q6qaeoq2o1oe.png&quot; alt=&quot;Structs&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here we created structs to house some data. Structs in Go are a way to group related data. I have found them to be some of the most useful data type collections to perform a variety of tasks with. The first named &lt;em&gt;APICred&lt;/em&gt; is just a way to house and reuse the API credentials that we grabbed from the Twitter App we created.&lt;/p&gt;

&lt;p&gt;The next structs are for the quote object we will be grabbing from the JSON file. We have a struct made for the individual quotes and one for an array of the aforementioned &lt;em&gt;QuoteObject&lt;/em&gt; structs. This makes it easier to grab all our quotes and use the list to set our bot logic. This is not an ideal solution as it assumes we will always grab all the quotes from the list. This is not a scalable solution as we would not want to grab all the entries from say a database and then sort through them manually. However, for this low threshold example, it works.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/e8vkx2t63h3c1txxaomc.png&quot; alt=&quot;Quotes JSON&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Quick Note&lt;/em&gt;
You will notice for the struct keys that they are all capitalized. This is good practice because for me it looks neater and some issues can come up when working with things like JSON data. When unmarshalling the data into struct fields those fields are only exported if they are capitalized. This allows the JSON package to use the field names to unmarshal the data from the JSON file for use in our bot. I learned this after seeing my data come up blank when grabbing the quotes from the file. You can also see the issue in this &lt;a href=&quot;https://stackoverflow.com/questions/32674913/why-struct-fields-are-showing-empty&quot;&gt;Stack Overflow&lt;/a&gt; article and save yourself some time.&lt;/p&gt;

&lt;p&gt;Another thing to note on the structs is the tags or annotations attached to the struct keys. In many cases, this might not be necessary. As in the case where everything is named the same on the JSON fields and the struct fields; The package should be smart enough to match them. However, I program as defensively as I can so the JSON tags allow for me to match them up directly. The annotations tell the JSON package that the &lt;em&gt;TweetId&lt;/em&gt; field needs to be matched with the &lt;em&gt;tweetid&lt;/em&gt; field in the JSON file. The tags do that for all of them. The &lt;em&gt;QuoteList&lt;/em&gt; field will grab that entire “quotes” block from the JSON file. This also works when working with binary JSON or BSON information, say from grabbing information from Mongo DB.&lt;/p&gt;

&lt;p&gt;Here is the next block of code for facilitating some functions in our bot:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/xc0q0lwjstmo0k53vfve.png&quot; alt=&quot;Load Env and Math&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now comes some more fun. When working with local files stuff like tokens, keys, DB params, etc we would use a .env file and import it into our code. In this case, we are not using this locally or on a production machine, we are creating an AWS Lambda function! The env variables can be set on the Lambda dashboard. On the code side, we do not need to load an environment library, we can just use the &lt;em&gt;os&lt;/em&gt; library to load our environment variables directly from AWS. Above we create a new instance of the APICred and call it &lt;em&gt;env&lt;/em&gt; and return that from the function. Here we make use of Go’s return type naming in the function signature to initialize our returned item. Then we set the fields and we are ready to party rock the Twitterverse.&lt;/p&gt;

&lt;p&gt;The next function is a helper function to come up with a random index used to randomly search for a quote to tweet out. We use the &lt;em&gt;math/rand&lt;/em&gt; library along with the &lt;em&gt;Seed&lt;/em&gt; function to get a random index within the range of quotes that we have. We serve a minimum index value which should always be 0 (maybe make a const next time?) and a max value. In this case, we will count the number of entries (quotes) and use that as the max value. We do this so that we can always come to an index with the range of quotes we have. In other words, if we have ten quotes we want to return an index between 0-10 and use that to match to the &lt;em&gt;tweetid&lt;/em&gt; field in the JSON file and grab a quote. The “Seed” function here is important as the &lt;a href=&quot;https://golang.org/pkg/math/rand/&quot;&gt;&lt;em&gt;rand&lt;/em&gt;&lt;/a&gt; function is deterministic. As in it will return the same value each time you run it. The “rand” function is considered pseudo-random for this reason. If &lt;em&gt;Seed&lt;/em&gt; is not called &lt;em&gt;rand&lt;/em&gt; will by default using Seed(1) which will get us the same number each time. By using the &lt;em&gt;Seed&lt;/em&gt; function to set the seed on each run and using the Unix time will make sure to feed in an int64 number representing the time that changes every second.&lt;/p&gt;

&lt;p&gt;Next, we come up with the logic to grab our quote:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/98neq9dup844koobm1gg.png&quot; alt=&quot;Grab Quote&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This function is used to get a quote and return it as a string to our API object, which then sends the string to Twitter. The first part is to grab the file and return a file object using the &lt;em&gt;os.Open&lt;/em&gt; function. This assumed the JSON file is in the same directory as the bot file. If not an error is thrown. We set up the &lt;em&gt;defer quote_file.Close()&lt;/em&gt; so that all the other logic in our function runs and the &lt;a href=&quot;https://tour.golang.org/flowcontrol/12&quot;&gt;defer&lt;/a&gt; runs last. This keeps our file open for us until we are done. This is great for flow control.&lt;/p&gt;

&lt;p&gt;Next, we need to convert what is in the files into a []byte list so that we can unmarshal the data. The &lt;em&gt;ioutil.ReadAll&lt;/em&gt; function call allows us to assign the contents of the file to a byte object. After that, we unmarshal the data using the &lt;em&gt;json&lt;/em&gt; package. Here we set it to unmarshal the &lt;em&gt;quotes_bytes&lt;/em&gt; object into a pointer for our quotes object which is initialized in the line above that. Here is where our annotations go to work and make everything work automagically. We set some error handling and then we get to work getting our quote.&lt;/p&gt;

&lt;p&gt;We set the maximum number of quote objects by referencing the &lt;em&gt;QuoteList&lt;/em&gt; field and counting the number of objects in the array. Next, we get our &lt;em&gt;random_tweetid&lt;/em&gt; which will grab a random index from zero to the max number of quotes. Finally, we get our quote by calling the &lt;em&gt;Quote&lt;/em&gt; field from one of the random indexes in our &lt;em&gt;QuoteList&lt;/em&gt; which returns a quote ready to be served to Twitter.&lt;/p&gt;

&lt;p&gt;The last part of our bot puts everything together and execute:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/r2ordt6btjy421b2wbgh.png&quot; alt=&quot;Send Tweet Main&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We load our environment variables using the APICred struct and using the Anaconda library we set our Consumer key and secret and then create the API instance using the access token and secret. Now with all the power at our fingertips, we call our &lt;em&gt;GrabQuote&lt;/em&gt; function which grabs a random quote from our JSON file and sets it to the &lt;em&gt;tweet&lt;/em&gt; variable. In the &lt;em&gt;PostTweet&lt;/em&gt; function call you can see that we pass in our quote via the &lt;em&gt;tweet&lt;/em&gt; object and we also pass in &lt;em&gt;url.Value{}&lt;/em&gt; which we can call from the &lt;em&gt;net/url&lt;/em&gt; library import. If you look through the Anaconda source, in the &lt;a href=&quot;https://github.com/ChimeraCoder/anaconda/blob/master/tweets.go&quot;&gt;&lt;em&gt;PostTweet&lt;/em&gt; function&lt;/a&gt; the url values are used to set some required API fields. Once those are set the library creates a channel to pass in all the fields to send to the API. Diving into how the libraries source is a good idea. You should know how every line in your program works. This includes knowing how a library handles inputs and outputs. We set some error handling, just in case, for the &lt;em&gt;PostTweet&lt;/em&gt; and we send the tweet through the API and into the timeline.&lt;/p&gt;

&lt;p&gt;Every Go program has the main function where everything is called. Here we utilize the &lt;a href=&quot;https://github.com/aws/aws-lambda-go/&quot;&gt;AWS Lambda for Go library&lt;/a&gt; to call our function. The &lt;em&gt;lambda.Start()&lt;/em&gt; is how Lambda will call our function. In our case, we house all the logic in the &lt;em&gt;SendTweet&lt;/em&gt; function and use the logic in &lt;em&gt;main()&lt;/em&gt; to call it. If we were creating say an API we would create a handler function which is called from the &lt;em&gt;lambda.Start()&lt;/em&gt; function. In our case I decided not to return anything however, Lambda allows for the return of between 0-2 arguments. This is good for returning logs of the events run and or errors. AWS Lambda offers great tools for logging the actions of your function and the returns are how they are recorded. If setting returns one of the returns must implement an error according to the docs. So you can say return a success log with some information you want to track and an error for when stuff goes wrong. AWS Lambda also allows for passing in between 0-2 function arguments. They do say in the &lt;a href=&quot;https://docs.aws.amazon.com/lambda/latest/dg/golang-handler.html&quot;&gt;documentation&lt;/a&gt; that if passing in an argument a context is required. I have not tested this yet, but I will, and I will probably write about it.&lt;/p&gt;

&lt;p&gt;Our bot is done! Let’s party.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/l0MYt5jPR6QX5pnqM/giphy.gif&quot; alt=&quot;Party!&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;but-wait-we-cant-party-yet&quot;&gt;But Wait, we can’t party yet!&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/6Q2KA5ly49368/giphy.gif&quot; alt=&quot;No party!&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Before that, we need to set up a way for our bot to run. It would suck to have to manually run this every time I want to send a quote. Might as well open an alt account and do it manually. It would suck even more to have to provision a cloud instance to run all day for the sake of posting a tweet once or twice a day. Screw that, let’s use Lambda.&lt;/p&gt;

&lt;h3 id=&quot;setting-up-a-lambda-function-&quot;&gt;Setting up a Lambda Function &lt;a name=&quot;lambda_function&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Here we are going to assume that we already have an AWS account set up. If you don’t go &lt;a href=&quot;https://aws.amazon.com/&quot;&gt;set it up&lt;/a&gt;. It’s useful to have. Now that we’re set up go find your AWS Management Console and search the services for Lambda:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/v87egsifh2tbbyvlr2mq.png&quot; alt=&quot;AWS Console Lambda&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Click Lambda and you will be brought to the Lambda screen. Here you can find a list for all your applications, functions, and layers. In addition to all that you have a dashboard dedicated to monitoring all your Lambda stuff.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/dlmagb2aqibrs5hev45z.png&quot; alt=&quot;Lambda Dash&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It will show the number of functions you have going, the storage used up by your functions, your concurrency, and tons of other stuff. We mentioned the pricing for Lambda; The prices vary depending on the amount you allocate. The pricing also takes into account the duration of time it takes for your functions to &lt;a href=&quot;https://aws.amazon.com/lambda/pricing/&quot;&gt;execute as well as the number of requests&lt;/a&gt;. For us, we are using far less than what is allowed on the free tier since we are only invoking once a day at this point. This will change as I further develop the project.&lt;/p&gt;

&lt;p&gt;Now, let’s make a function:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/is526vjii3cz4b9nu0ps.png&quot; alt=&quot;Lambda Home&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On the next screen, we have some information to fill out. The first is authoring options. Here we can leave the default “Author from scratch” option selected. There is also the option for using blueprints to develop our app. If you select this, you are given a list of different already made sample projects which you can use to quickly develop apps. You can also filter out what you are looking for. This makes it easier to quickly prototype an app and start standing up your back end. There is also another option to &lt;em&gt;Browse serverless app repository&lt;/em&gt; where you have a similar solution for quickly standing up apps. For our purposes, we are going to author from scratch.&lt;/p&gt;

&lt;p&gt;We put in our function name and select the runtime. The runtime we will circle back to but be sure to select &lt;em&gt;Go 1.x&lt;/em&gt; which will set us up to use Golang as our function language. For the permissions, we default to &lt;em&gt;Create a new role with basic Lambda permissions&lt;/em&gt; which is fine for now. If you have existing roles created in your IAM console you can feel free to use one. Just be sure that the role has the correct permissions for running Lambda functions. You can also &lt;em&gt;Create a new role from AWS policy templates&lt;/em&gt; which allows you to create a role using policy templates built by AWS.&lt;/p&gt;

&lt;p&gt;Now we are ready to stand up our function. We are taken to the home page for the function. Here we can start setting up everything:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/xqzi01xpnwqrxxaeudfe.png&quot; alt=&quot;Function Home&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first thing we are going to do is set our environment variables. As I mentioned above, we are not loading in an env library and we are getting our variables directly from AWS. Here is where we set those up:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/0oerc7nt6oiyxxv5mokc.png&quot; alt=&quot;Env Vars&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you scroll down you will come to a section labeled &lt;em&gt;Environment variables&lt;/em&gt;, hit the &lt;em&gt;Edit&lt;/em&gt; button and you are taken to the next page where we can set up our vars. If you hit the &lt;em&gt;Add environment variable&lt;/em&gt; you can start entering in all your needed variables. In our case, we set up one for the consumer key, consumer secret, access key, and access secret. As noted in our code we will import them in our code using the &lt;em&gt;os.GetEnv&lt;/em&gt; function. AWS even notes in the margins how this is done for each language. So spice. AWS lets us set up encryption for our variables as well. This will allow for sensitive information (like API credentials) to be encrypted on the Lambda console and when being used by the API. AWS provides a Key Management API service for encrypting and decrypting your &lt;a href=&quot;https://docs.aws.amazon.com/kms/latest/APIReference/Welcome.html&quot;&gt;sensitive information&lt;/a&gt;. I will not go into how to use the API here but setting up encryption is probably a good idea, so I will write a follow up about it at some point. Once all our variables are set, we can go back to the main page and upload our code.&lt;/p&gt;

&lt;p&gt;The function code is usually available for editing in the “Function Code” section. There a Cloud9 IDE is set up for looking at and editing our code. I have used it and it is a useful tool. I don’t think it is compatible with the Golang runtime though. I will come back to this as I ran into issues when building my function.&lt;/p&gt;

&lt;p&gt;Now we have to bundle our code and put it into AWS through our newly made function. As mentioned above I used Windows to create this package so I will go over what I did as reflected in the docs. However, I ran into issues when using Windows to do this. Based on my experimenting and some &lt;a href=&quot;https://twitter.com/georgeoffley/status/1291483070797881346&quot;&gt;feedback from some smart people&lt;/a&gt; I found that I needed to use a Unix based endpoint to build out the project. I will break down why after.&lt;/p&gt;

&lt;p&gt;Once we have everything set to go on the AWS side, we are ready to build our package. So CMD your way to the root of the package. Now we will set our build environment to Linux using this command:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Set GOOS=linux
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We do this to set the build command to tell the compiler to use the Linux binary. So far as I can tell this is a bit of a known issue with using Windows to do all this. This has not been solved as of the publication of this, but I am sure a fix will come through. Earlier when we set our runtime to &lt;em&gt;Go 1.x&lt;/em&gt; we were also setting the server operating system which runs our function. When we say “serverless” we mean someone else’s servers. In this case when setting the Go run time we are setting the OS to run the &lt;a href=&quot;https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html&quot;&gt;Amazon Linux operating system&lt;/a&gt;. Amazon Linux is a server operating system made to run AWS based services. You can also create images using Amazon Linux for running tons of stuff.&lt;/p&gt;

&lt;p&gt;After we set the binary, we can build our package:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;go build -o main bot.go
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is important to make sure our executable is &lt;a href=&quot;https://docs.aws.amazon.com/lambda/latest/dg/golang-handler.html&quot;&gt;called main&lt;/a&gt;. As the main function is the invocation point and we are going to set the handler to run main. We need to upload the executable created by the build command to our Lambda function as a zip file. So we send our main executable to a zip file. In our case, we need to zip up the main executable and the &lt;em&gt;quotes.json&lt;/em&gt; file since we will need that for our quotes. I did this manually but there is a command you can run for zipping up everything. Shown below:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%USERPROFILE%\Go\bin\build-lambda-zip.exe -output main.zip main
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Quick Note:&lt;/em&gt;
So far as I can tell when you zip the contents of the package using Windows it retains Windows permissions. Retention of POSIX permissions is a known issue with using Lambda cross-platform. POSIX permissions are a Unix standard which defines the permission structure used to interact with files and applications. From what I can tell these permissions are not set correctly when doing all this in Windows. However, when I used my Mac (a Unix based OS) I was able to build and test my function without issue.&lt;/p&gt;

&lt;p&gt;After we zip up our executable and our quotes file we can navigate down to the “Function code” and upload our zip:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/riozbculg7jqpp74bkig.png&quot; alt=&quot;Function Code Upload&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Select the &lt;em&gt;Upload as zip&lt;/em&gt; option and we can upload our newly created zip file.&lt;/p&gt;

&lt;p&gt;The final step is we need to scroll down to the &lt;em&gt;Basic Settings&lt;/em&gt; section and select &lt;em&gt;Edit&lt;/em&gt;. The edit basic settings page is where we can set a description, change our run time, edit the handler, set the memory, set a time out period, and edit the Execution rule. One thing to note is the memory that you can set to whatever you would like. The default 512 MB is fine, especially in our case. But keep in mind that the more memory the more it may cost. Additionally, you may not need all the memory you set and that could end up costing you money needlessly. For our purposes, it’s fine where it is.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/0cjy6vn5dlcj8irgyxfi.png&quot; alt=&quot;Edit Basic Settings&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We need to edit the handler and set that to &lt;em&gt;main&lt;/em&gt;. As I mentioned above, we are using the main handler to invoke our executable within Lambda. So, make sure that when you build your package you name it as &lt;em&gt;main&lt;/em&gt; so that the handler will work.&lt;/p&gt;

&lt;p&gt;Congrats! Now that we are set up, but wait! We should test this. On the top right of the function home page, there is a drop-down for selecting a test to run. Clicking this gives us the option for setting up a new test. You can use this to set up regular scenarios, edge cases, or any other specific tests you want to run. For us we just need to hit “Configure test events” and this will bring up the test creation page:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/o08kjt1xyouajibg280c.png&quot; alt=&quot;Configure Tests&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here we will want to select the &lt;em&gt;Create new test event&lt;/em&gt; which will allow us to select an event template. The default &lt;em&gt;Hello World&lt;/em&gt; template is fine for now but there are built-in test templates which you can choose from depending on your needs. Once this test is created it can be used as a test template for our function. You can leave the default JSON there, and make sure to name your test event. The JSON can be edited to accommodate whatever you are using. For example, we can test the ability to run a Lambda function via an &lt;a href=&quot;https://youtu.be/YvT_gqs5ETk&quot;&gt;Alexa trigger&lt;/a&gt;. So, the testing JSON file would be where you would pass in echo API session information. For now, the default is fine, when we’re done hit &lt;em&gt;Create&lt;/em&gt;. Now we can test our function by hitting the &lt;em&gt;Test&lt;/em&gt; button:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/aj5qsebu3b88x3mb4ewd.png&quot; alt=&quot;Run test&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Huzzah!&lt;/strong&gt; We tested good. Now what? Well, I think we would like to run this bot on a schedule. Lambda allows for a lot of different triggers but for our purposes, we want to run on a regular schedule. Like a cron job. To do this we select the &lt;em&gt;Add trigger&lt;/em&gt; button on the &lt;em&gt;Designer&lt;/em&gt; section of our function home.&lt;/p&gt;

&lt;p&gt;Then we are taken to the trigger page where we want to search for &lt;em&gt;EventBridge&lt;/em&gt; (formally CloudWatch Events).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/o3wh4ame3qtm7d12axln.png&quot; alt=&quot;Trigger Select&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Next, we hit select the rule for EventBridge:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/i/4iduspcpde9y1hihvrff.png&quot; alt=&quot;Trigger Config&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can reuse old rules we have created or we can hit the &lt;em&gt;Create a new rule&lt;/em&gt; option. That opens a bunch of configuration options. We can set the name of the rule, whether it is scheduled or based on an event, and if we want to enable the trigger. We want to schedule this to run daily so we select the &lt;em&gt;Schedule expression&lt;/em&gt; option and then enter &lt;em&gt;cron(0 12 * * ? *)&lt;/em&gt; as our expression. This is an awesome &lt;a href=&quot;https://crontab.guru/&quot;&gt;reference for the cron syntax&lt;/a&gt;. This is set to run daily at noon Keep in mind for cron expressions UTC is used. This will run every day at noon UTC. Then we hit save. Now we are done! We have officially added to the background noise of Twitter!&lt;/p&gt;

&lt;h3 id=&quot;conclusion-&quot;&gt;Conclusion &lt;a name=&quot;conclusion&quot;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Doing this allowed me to check out how cool and simple running stuff off Lambda is. I most likely will continue to do stuff with it as I continue to develop this project. A couple of things I will experiment with is using a Cloud9 IDE available in AWS to develop things like this. It is Unix based so performing the build functions won’t pose too many new issues. It looks as if AWS is bringing the users to the cloud, even by force if needed. It’s not a bad thing though, nothing is perfect, and this is a great solution for running serverless back end services.&lt;/p&gt;

&lt;p&gt;The second part of this series will focus on integrating a database into our Lambda function. Putting six quotes in a JSON file might be an interesting challenge to pull from but it hardly makes for a good way to send out information or useless quotes in our case. I am also going to explore possible language interpretation to create a trained bot that throws out randomly generated quotes based on input data. I’m not looking to replicate the racism, sexism, and pure unadulterated horribleness flying through the Twitter pipes. So, it will be an interesting challenge to try and filter much of that out. We shall see. For now, use Lambda, it’s awesome!&lt;/p&gt;

&lt;h3 id=&quot;now-we-can-actually-party&quot;&gt;Now we can actually party!&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/wolS1Hp8Rtrig/giphy.gif&quot; alt=&quot;Party&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;full-github-code&quot;&gt;&lt;a href=&quot;https://github.com/georgeoffley/TechBroBot&quot;&gt;Full Github Code&lt;/a&gt;&lt;/h4&gt;
&lt;h4 id=&quot;aws-docs&quot;&gt;&lt;a href=&quot;https://docs.aws.amazon.com/lambda/index.html&quot;&gt;AWS Docs&lt;/a&gt;&lt;/h4&gt;
</description>
        <pubDate>Sat, 08 Aug 2020 23:56:00 -0400</pubDate>
        <link>https://georgeoffley.com/blog/creating-a-twitter-bot-using-aws-lambda-and-go.html</link>
        <guid isPermaLink="true">https://georgeoffley.com/blog/creating-a-twitter-bot-using-aws-lambda-and-go.html</guid>
        
        <category>AWS</category>
        
        <category>Go</category>
        
        
        <category>Blog</category>
        
      </item>
    
  </channel>
</rss>
